19 de Febrero 2020
- Hacer stemming con SnowballStemmer ("spanish")
- Implemetar frecuencia normalizada (Probabilidad).
	
	1. Stemming de Snowball + frec original
	2. Stemming de Snowball + probabilidad

----------------------------------------------------------
21 de Febrero 2020
Tenemos una lista de frecuencias:
grande = ('5, 0, 1, 3, 0, 5')

1. Pasar el vector de grande, con el de tf(frec) = [(k+1)*Frec]/(k + frec)
v_probab = vec_frecuencia/ np.sum(vec_frecuenncia)

v_tf = ((k + 1) * vec_frecuencias) / (vec_frecuencias + k)
k = 0.7, puede ser otro (Search value for k in BM25 = 1.2)

IDF(W) = log[(M+1)/K]

Para cada palabra del vocabulario ordenado, poner el número de contextos dónde esta esta palabra. (De nuestro diccionario de contextos):
Document_freq = (5, 1, 20, ..., 3)
k : Número de contextos donde esta la palabra W
M : Tamaño del vocabulario

tf - idf = tf * idf
vector_de_contexto = np.multiply(vec_tf * vec_idf)

	3. Stemming de Snowball + (tf - idf)


¿Qué tan compatibles son dos palabras en una oración?

--->>
Syntagmatic Relation = Correlated Ocurrences
X_w es la variable aleatoria

	4. Leer capítulo 6 y 13 del libro Text Data Management and Analysis.
	5. Descargar paquete de python GENSIM